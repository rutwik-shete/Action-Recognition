{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import argument_parser\n",
    "from data_manager import BlockFrameDataset\n",
    "from data_split import split_data\n",
    "from model import CustomModel\n",
    "from AverageMeter import AverageMeter\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS GPU\n",
      "Initializing Dataloader\n"
     ]
    }
   ],
   "source": [
    "# Code For GPU Selection\n",
    "has_cuda = True if torch.has_cuda else False\n",
    "has_mps = True if torch.has_mps else False\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if has_cuda :\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using Cuda GPU\")\n",
    "\n",
    "elif has_mps :\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using MPS GPU\")\n",
    "\n",
    "else :\n",
    "    warnings.warn(\"Using SPU , GPU is Recommended\")\n",
    "\n",
    "print(\"Initializing Dataloader\")\n",
    "\n",
    "#Split Dataset\n",
    "train_data,val_data,test_data = split_data(\"./dataset\")\n",
    "\n",
    "val_dataset = BlockFrameDataset(\"./dataset\",val_data,block_size=8)\n",
    "train_dataset = BlockFrameDataset(\"./dataset\",train_data,block_size=8)\n",
    "test_dataset = BlockFrameDataset(\"./dataset\",test_data,block_size=8)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,shuffle=True,batch_size=20,num_workers=1, pin_memory=True)\n",
    "train_loader = DataLoader(train_dataset,shuffle=True,batch_size=20,num_workers=1, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset,shuffle=True,batch_size=20,num_workers=1, pin_memory=True)\n",
    "\n",
    "# Procuring the pretrained model\n",
    "\n",
    "model,processor = CustomModel()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, processor, data_loader, optimizer, device):\n",
    "    # meter\n",
    "    loss_meter = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    tk = tqdm(data_loader, total=int(len(data_loader)), desc='Training', unit='frames', leave=False)\n",
    "    for batch_idx, data in enumerate(tk):\n",
    "        # fetch the data\n",
    "        frame, label = data[0], data[1]\n",
    "        frame = torch.squeeze(frame)\n",
    "        label = label\n",
    "        # after fetching the data, transfer the model to the \n",
    "        # required device, in this example the device is gpu\n",
    "        # transfer to gpu can also be done by \n",
    "        frame, label = frame.to(device), label.to(device)\n",
    "        # compute the forward pass\n",
    "        output = model(frame)\n",
    "        logits = output.logits\n",
    "        # predicted_class_idx = logits.argmax(-1).item()\n",
    "\n",
    "\n",
    "        # print(\"Frame : \",frame[0].shape,\" Label: \",label,\" Output: \",output,\" Predicted : \",predicted_class_idx)\n",
    "        # compute the loss function\n",
    "        loss_this = F.cross_entropy(logits, label)\n",
    "        # initialize the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # compute the backward pass\n",
    "        loss_this.backward()\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "        # update the loss meter\n",
    "        loss_meter.update(loss_this.item(), label.shape[0])\n",
    "        tk.set_postfix({\"loss\": loss_meter.avg})\n",
    "    print('Train: Average loss: {:.4f}\\n'.format(loss_meter.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd358038cf444ef0865c573997a9c88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/135 [00:00<?, ?frames/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "Train: Average loss: 0.5880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model,processor,train_loader,optimizer,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    # meters\n",
    "    loss_meter = AverageMeter()\n",
    "    acc_meter = AverageMeter()\n",
    "    # switch to test mode\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    tk = tqdm(data_loader, total=int(len(data_loader)), desc='Test', unit='frames', leave=False)\n",
    "    for batch_idx, data in enumerate(tk):\n",
    "        # fetch the data\n",
    "        frame, label = data[0], data[1]\n",
    "        frame = torch.squeeze(frame)\n",
    "        # after fetching the data transfer the model to the \n",
    "        # required device, in this example the device is gpu\n",
    "        # transfer to gpu can also be done by \n",
    "        frame, label = frame.to(device), label.to(device)\n",
    "        # since we dont need to backpropagate loss in testing,\n",
    "        # we dont keep the gradient\n",
    "        with torch.no_grad():\n",
    "            output = model(frame)\n",
    "        \n",
    "        logits = output.logits\n",
    "        # compute the loss function just for checking\n",
    "        loss_this = F.cross_entropy(logits, label)\n",
    "        # get the index of the max log-probability\n",
    "        pred = logits.argmax(dim=1, keepdim=True)\n",
    "        # check which of the predictions are correct\n",
    "        correct_this = pred.eq(label.view_as(pred)).sum().item()\n",
    "        # accumulate the correct ones\n",
    "        correct += correct_this\n",
    "        # compute accuracy\n",
    "        acc_this = correct_this / label.shape[0] * 100.0\n",
    "        # update the loss and accuracy meter \n",
    "        acc_meter.update(acc_this, label.shape[0])\n",
    "        loss_meter.update(loss_this.item(), label.shape[0])\n",
    "    print('Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        loss_meter.avg, correct, len(data_loader.dataset), acc_meter.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78105e41ce364b359ea8537a71bd75e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/19 [00:00<?, ?frames/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Average loss: 0.9385, Accuracy: 262/363 (72.18%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model,test_loader,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLG_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96c612e4d8bae94af11c2cc0f32112bc866728224438298ff625d50e73810858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
